{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Lengh</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>W-Height</th>\n",
       "      <th>S-Height</th>\n",
       "      <th>V-Height</th>\n",
       "      <th>S-Height.1</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex   Lengh   Diameter   Height   W-Height   S-Height   V-Height  \\\n",
       "0    0   0.455      0.365    0.095     0.5140     0.2245     0.1010   \n",
       "1    0   0.350      0.265    0.090     0.2255     0.0995     0.0485   \n",
       "2    1   0.530      0.420    0.135     0.6770     0.2565     0.1415   \n",
       "3    0   0.440      0.365    0.125     0.5160     0.2155     0.1140   \n",
       "4    2   0.330      0.255    0.080     0.2050     0.0895     0.0395   \n",
       "\n",
       "    S-Height.1   Class  \n",
       "0        0.150      15  \n",
       "1        0.070       7  \n",
       "2        0.210       9  \n",
       "3        0.155      10  \n",
       "4        0.055       7  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe\n",
    "data = pd.read_csv(\"input.csv\")\n",
    "df_data = pd.DataFrame(data)\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function the create new set every run\n",
    "def data_shufle(df_data):\n",
    "    \n",
    "    # Shuffle the data\n",
    "    df_data = sk.utils.shuffle(df_data)\n",
    "    df_data_norm = df_data.drop(columns=[\"Class\"])    \n",
    "    \n",
    "    # Split the data\n",
    "    x_train, x_temp, y_train, y_temp = train_test_split(df_data_norm, df_data[\"Class\"], test_size=0.5)\n",
    "    x_validation, x_test, y_validation, y_test = train_test_split(x_temp, y_temp, test_size=0.5)\n",
    "\n",
    "    return x_train, x_validation, x_test, y_train, y_validation, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "def KNR_model(x_train, x_validation, y_train, y_validation):\n",
    "    \n",
    "    best_rmse = float('inf')\n",
    "    \n",
    "    # Find the best configuration\n",
    "    for k in range(1, 50):\n",
    "        for i in range(\"uniform\", \"distance\"):\n",
    "            knn_inst = KNeighborsRegressor(n_neighbors=k, weights=i)\n",
    "            knn_inst.fit(x_train, y_train)\n",
    "            knn_validation = knn_inst.predict(x_validation)\n",
    "            mse = sk.metrics.mean_squared_error(y_validation, knn_validation)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            # See if is the best model\n",
    "            if(rmse < best_rmse):\n",
    "                best_rmse = rmse\n",
    "                best_k = k\n",
    "                best_dist = i\n",
    "                best_KNR = knn_inst\n",
    "                \n",
    "    return best_KNR, best_k, best_dist\n",
    "\n",
    "\n",
    "def KNR(x_train, x_validation, x_test, y_train, y_validation, y_test):\n",
    "    \n",
    "    # Create the model\n",
    "    best_KNR, best_k, best_dist = KNR_model(x_train, x_validation, y_train, y_validation)\n",
    "    \n",
    "    # Predict the test data\n",
    "    knn_test = best_KNR.predict(x_test)\n",
    "    \n",
    "    # Calculate the error\n",
    "    mse = sk.metrics.mean_squared_error(y_test, knn_test)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return best_KNR, best_k, best_dist, rmse\n",
    "    \n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "def SVM_model(x_train, x_validation, y_train, y_validation):\n",
    "    \n",
    "    best_rmse = float('inf')\n",
    "    \n",
    "    # State the parameters\n",
    "    parameters_grid = { \"kernel\": [\"linear\", \"poly\", \"rbf\", \"sigmoid\"], \n",
    "                        \"C\": [0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "    \n",
    "    # Find the best configuration\n",
    "    for i in ParameterGrid(parameters_grid):\n",
    "        svm_inst = SVR(**i)\n",
    "        svm_inst.fit(x_train, y_train)\n",
    "        svm_validation = svm_inst.predict(x_validation)\n",
    "        mse = sk.metrics.mean_squared_error(y_validation, svm_validation)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # See if is the best model\n",
    "        if(rmse < best_rmse):\n",
    "            best_rmse = rmse\n",
    "            best_params = i\n",
    "            best_SVM = svm_inst\n",
    "            \n",
    "    return best_SVM, best_params\n",
    "\n",
    "def SVM(x_train, x_validation, x_test, y_train, y_validation, y_test):\n",
    "    \n",
    "    # Create the model\n",
    "    best_SVM, best_params = SVM_model(x_train, x_validation, y_train, y_validation)\n",
    "    \n",
    "    # Predict the test data\n",
    "    svm_test = best_SVM.predict(x_test)\n",
    "    \n",
    "    # Calculate the error\n",
    "    mse = sk.metrics.mean_squared_error(y_test, svm_test)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return best_SVM, *best_params, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "def MLP_model(x_train, x_validation, y_train, y_validation):\n",
    "    \n",
    "    best_rmse = float('inf')\n",
    "    \n",
    "    # Parameters to be used\n",
    "    parameters_grid = { \"hidden_layer_sizes\": [(100, 50, 25), (21, 14, 1), (100, 100, 100)],\n",
    "                        \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "                        \"max_iter\": [1000, 2000],\n",
    "                        \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "    }\n",
    "    \n",
    "    # Find the best configuration\n",
    "    for i in ParameterGrid(parameters_grid):\n",
    "        mlp_inst = MLPRegressor(**i)\n",
    "        mlp_inst.fit(x_train, y_train)\n",
    "        mlp_validation = mlp_inst.predict(x_validation)\n",
    "        mse = sk.metrics.mean_squared_error(y_validation, mlp_validation)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # Save the best model\n",
    "        if (rmse < best_rmse):\n",
    "            best_rmse = rmse\n",
    "            best_params = i\n",
    "            best_MLP = mlp_inst\n",
    "        \n",
    "    return best_MLP, best_params\n",
    "\n",
    "\n",
    "def MLP(x_train, x_validation, x_test, y_train, y_validation, y_test):\n",
    "    \n",
    "    # Create the model\n",
    "    best_MLP, best_params = MLP_model(x_train, x_validation, y_train, y_validation)\n",
    "    \n",
    "    # Predict the data\n",
    "    mlp_test = best_MLP.predict(x_test)\n",
    "    \n",
    "    # Calculate the error\n",
    "    mse = sk.metrics.mean_squared_error(y_test, mlp_test)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return best_MLP, *best_params, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def RF_model(x_train, x_validation, y_train, y_validation):\n",
    "    \n",
    "    best_rmse = float('inf')\n",
    "    \n",
    "    # Parameters to be used\n",
    "    parameters_grid = { \"hidden_layer_sizes\": [(100, 50, 25), (21, 14, 1), (100, 100, 100)],\n",
    "                        \"activation\": [\"identity\", \"logistic\", \"tanh\", \"relu\"],\n",
    "                        \"max_iter\": [1000, 2000],\n",
    "                        \"learning_rate\": [\"constant\", \"invscaling\", \"adaptive\"]\n",
    "    }\n",
    "    \n",
    "    # Find the best config\n",
    "    for i in ParameterGrid(parameters_grid):\n",
    "        rf_inst = RandomForestRegressor(**i)\n",
    "        rf_inst.fit(x_train, y_train)\n",
    "        rf_validation = rf_inst.predict(x_validation)\n",
    "        mse = sk.metrics.mean_squared_error(y_validation, rf_validation)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # Save the best model\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_model = rf_inst\n",
    "            best_params = i\n",
    "            \n",
    "    return best_model, best_params\n",
    "\n",
    "def RF(x_train, x_validation, x_test, y_train, y_validation, y_test):\n",
    "    \n",
    "    # Create the model\n",
    "    best_RF, best_params = RF_model(x_train, x_validation, y_train, y_validation)\n",
    "    \n",
    "    # Predict the data\n",
    "    rf_test = best_RF.predict(x_test)\n",
    "    \n",
    "    # Calculate the error\n",
    "    mse = sk.metrics.mean_squared_error(y_test, rf_test)\n",
    "    rmse = np.sqrt(mse)   \n",
    "    \n",
    "    return best_RF, *best_params, rmse  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "def GB_model(x_train, x_validation, y_train, y_validation):\n",
    "    \n",
    "    best_rmse = float('inf')\n",
    "    \n",
    "    # Parameters to be used\n",
    "    parameters_grid = { \"n_estimators\": [10, 50, 100],\n",
    "                        \"loss\": [\"squared_error\", \"quantile\", \"absolute_error\", \"huber\"],\n",
    "                        \"max_depth\": [None, 10, 50], \n",
    "                        \"learning_rate\": [0.1, 0.5, 1.0],\n",
    "                        \"min_samples_split\": [2, 5, 10], \n",
    "                        \"min_samples_leaf\": [1, 2, 4],\n",
    "    }\n",
    "    \n",
    "    # Find the best config\n",
    "    for i in ParameterGrid(parameters_grid):\n",
    "        gb_inst = GradientBoostingRegressor(**i)\n",
    "        gb_inst.fit(x_train, y_train)\n",
    "        gb_validation = gb_inst.predict(x_validation)\n",
    "        mse = sk.metrics.mean_squared_error(y_validation, gb_validation)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # Save the best model\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_model = gb_inst\n",
    "            best_params = i\n",
    "            \n",
    "    return best_model, best_params\n",
    "\n",
    "def GB(x_train, x_validation, x_test, y_train, y_validation, y_test):\n",
    "        \n",
    "    # Create the model\n",
    "    best_GB, best_params = GB_model(x_train, x_validation, y_train, y_validation)\n",
    "    \n",
    "    # Predict the data\n",
    "    gb_test = best_GB.predict(x_test)\n",
    "    \n",
    "    # Calculate the error\n",
    "    mse = sk.metrics.mean_squared_error(y_test, gb_test)\n",
    "    rmse = np.sqrt(mse)   \n",
    "    \n",
    "    return best_GB, *best_params, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def MLR(x_train, x_validation, x_test, y_train, y_validation, y_test):\n",
    "    \n",
    "    # Create the model\n",
    "    mlr_inst = LinearRegression()\n",
    "    mlr_inst.fit(x_train, y_train)\n",
    "    \n",
    "    # Predict the data\n",
    "    mlr_test = mlr_inst.predict(x_validation)\n",
    "    \n",
    "    # Calculate the error\n",
    "    mse = sk.metrics.mean_squared_error(y_test, mlr_test)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return mlr_inst, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Class'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/mclovin/Regression/Main.ipynb Cell 19\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mclovin/Regression/Main.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Function to run the models\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mclovin/Regression/Main.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mclovin/Regression/Main.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m     \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mclovin/Regression/Main.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39m# Create the sets\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mclovin/Regression/Main.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m     data_shufled \u001b[39m=\u001b[39m data_shufle(df_data)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mclovin/Regression/Main.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39m# Run the models and save the results\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mclovin/Regression/Main.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     best_KNR, \u001b[39m*\u001b[39mbest_params_KNR, rmse_KNR \u001b[39m=\u001b[39m KNR(\u001b[39m*\u001b[39mdata_shufled)\n",
      "\u001b[1;32m/home/mclovin/Regression/Main.ipynb Cell 19\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mclovin/Regression/Main.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdata_shufle\u001b[39m(df_data):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mclovin/Regression/Main.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mclovin/Regression/Main.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# Shuffle the data\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mclovin/Regression/Main.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     df_data \u001b[39m=\u001b[39m sk\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mshuffle(df_data)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mclovin/Regression/Main.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     df_data_norm \u001b[39m=\u001b[39m df_data\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mClass\u001b[39;49m\u001b[39m\"\u001b[39;49m])    \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mclovin/Regression/Main.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39m# Split the data\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mclovin/Regression/Main.ipynb#X31sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     x_train, x_temp, y_train, y_temp \u001b[39m=\u001b[39m train_test_split(df_data_norm, df_data[\u001b[39m\"\u001b[39m\u001b[39mClass\u001b[39m\u001b[39m\"\u001b[39m], test_size\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n",
      "File \u001b[0;32m~/Regression/python/lib/python3.11/site-packages/pandas/core/frame.py:5347\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   5200\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5201\u001b[0m     labels: IndexLabel \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5208\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5209\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5210\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5211\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5212\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5345\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5346\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5347\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   5348\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   5349\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5350\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   5351\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   5352\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   5353\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5354\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   5355\u001b[0m     )\n",
      "File \u001b[0;32m~/Regression/python/lib/python3.11/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4713\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Regression/python/lib/python3.11/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Regression/python/lib/python3.11/site-packages/pandas/core/indexes/base.py:6992\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6990\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   6991\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 6992\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m.\u001b[39mtolist()\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   6993\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   6994\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Class'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Create the output dataframes\n",
    "output = pd.DataFrame(columns=[\"KNN\", \"SVM\", \"MLP\", \"RF\", \"GB\", \"MLR\"])\n",
    "\n",
    "KNR_params = pd.DataFrame(\n",
    "    columns=[\"k\", \n",
    "             \"dist\"])\n",
    "\n",
    "SVM_params = pd.DataFrame(\n",
    "    columns=[\"kernel\", \n",
    "             \"C\"])\n",
    "\n",
    "MLP_params = pd.DataFrame(\n",
    "    columns=[\"hidden_layer_sizes\", \n",
    "             \"activation\", \n",
    "             \"max_iter\", \n",
    "             \"learning_rate\"])\n",
    "\n",
    "RF_params = pd.DataFrame(\n",
    "    columns=[\"hidden_layer_sizes\", \n",
    "             \"activation\", \n",
    "             \"max_iter\", \n",
    "             \"learning_rate\"])\n",
    "\n",
    "GB_params = pd.DataFrame(\n",
    "    columns=[\"n_estimators\", \n",
    "             \"loss\", \n",
    "             \"max_depth\", \n",
    "             \"learning_rate\", \n",
    "             \"min_samples_split\", \n",
    "             \"min_samples_leaf\"])\n",
    "\n",
    "\n",
    "# Function to run the models\n",
    "for i in range(1):\n",
    "    \n",
    "    # Create the sets\n",
    "    data_shufled = data_shufle(df_data)\n",
    "    \n",
    "    # Run the models and save the results\n",
    "    best_KNR, *best_params_KNR, rmse_KNR = KNR(*data_shufled)\n",
    "    KNR_params.loc[len(KNR_params.index)] = best_params_KNR\n",
    "    \n",
    "    best_SVM, *best_params_SVM, rmse_SVM = SVM(*data_shufled)\n",
    "    SVM_params.loc[len(SVM_params.index)] = best_params_SVM\n",
    "    \n",
    "    best_MLP, *best_params_MLP, rmse_MLP = MLP(*data_shufled)\n",
    "    MLP_params.loc[len(MLP_params.index)] = best_params_MLP\n",
    "    \n",
    "    best_RF, *best_params_RF, rmse_RF = RF(*data_shufled)\n",
    "    RF_params.loc[len(RF_params.index)] = best_params_RF\n",
    "    \n",
    "    best_GB, *best_params_GB, rmse_GB = GB(*data_shufled)\n",
    "    GB_params.loc[len(GB_params.index)] = best_params_GB\n",
    "    \n",
    "    best_MLR, rmse_MLR = MLR(*data_shufled)\n",
    "    \n",
    "    # Show models accuracy\n",
    "    print(\"============Run: \", i, \"============\")\n",
    "    print(\"KNN: \", rmse_KNR)\n",
    "    print(\"SVM: \", rmse_SVM)\n",
    "    print(\"MLP: \", rmse_MLP)\n",
    "    print(\"RF: \", rmse_RF)\n",
    "    print(\"GB: \", rmse_GB)\n",
    "    print(\"MLR: \", rmse_MLR)\n",
    "    print(\"==============================\")\n",
    "    \n",
    "    # Save the results\n",
    "    output.loc[len(output.index)] = [rmse_KNR, rmse_SVM, rmse_MLP, rmse_RF, rmse_GB, rmse_MLR]\n",
    "    \n",
    "\n",
    "# Generate the output\n",
    "output.to_csv(\"output.csv\")\n",
    "\n",
    "# Generate the parameters\n",
    "KNR_params.to_csv(\"data/KNR_params.csv\")\n",
    "SVM_params.to_csv(\"data/SVM_params.csv\")\n",
    "MLP_params.to_csv(\"data/MLP_params.csv\")\n",
    "RF_params.to_csv(\"data/RF_params.csv\")\n",
    "GB_params.to_csv(\"data/GB_params.csv\")\n",
    "  \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
